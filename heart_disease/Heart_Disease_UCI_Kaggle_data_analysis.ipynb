{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart Disease UCI_Kaggle data analysis.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1_HRTA7YPWdOIji4aWvIboHYMiLvhFKPq",
      "authorship_tag": "ABX9TyNtZUuY7Wt0TB/qhL5JkJ08",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roseberr/data-analysis/blob/master/keggle/heart_disease/Heart_Disease_UCI_Kaggle_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcrVy4cTMTPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sklearn\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torchvision\n",
        "import torchtext\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Ge0GHElg4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/roseberr/data-analysis.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xccy9b7Kjvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heart_df=pd.read_csv('/content/drive/My Drive/Colab Notebooks/데이터분석 /heart disease_keggle/heart.xls')\n",
        "\n",
        "heart_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw4TJm6pKziu",
        "colab_type": "text"
      },
      "source": [
        "기본적인 값 확인과 NA없는 data 확인 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-8mEnXBMsvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(heart_df.head)\n",
        "print(heart_df.shape)\n",
        "\n",
        "print(heart_df.info())\n",
        "print(heart_df.isnull().sum())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msujshdRK-wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(heart_df.isnull().sum())#이상치 개수 확인\n",
        "print(heart_df.dropna(axis=0,inplace=True))#na인 행 제거"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfCz_ElPLVzB",
        "colab_type": "text"
      },
      "source": [
        "histogram 그리기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx8nFKQXLNpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_histograms(dataframe, features, rows, cols):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    for i, feature in enumerate(features):\n",
        "        ax = fig.add_subplot(rows, cols, i + 1)\n",
        "        dataframe[feature].hist(bins=20, ax=ax, facecolor='midnightblue')\n",
        "        ax.set_title(feature + \" Distribution\", color='DarkRed')\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "draw_histograms(heart_df,heart_df.columns,6,3) #histogram 출력"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xplWogUUMZ2-",
        "colab_type": "text"
      },
      "source": [
        "한국말 패치\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I54jh4mfMInf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EszQOlJEL7Jx",
        "colab_type": "text"
      },
      "source": [
        "sex count graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iO2pXRLLYUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(heart_df.describe())\n",
        "sn.barplot(x=\"sex\", y=\"target\", data=heart_df)\n",
        "sn.countplot(x=\"sex\",data=heart_df)\n",
        "\n",
        "plt.title(\"요일 별, 전체 팁\")\n",
        "plt.show()\n",
        "\n",
        "heart_df['sex'] = heart_df.sex.map({0: 'female', 1: 'male'})##이름 rename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRAIt5gQMiq6",
        "colab_type": "text"
      },
      "source": [
        "sex와 target의 상관그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCVlAYwbMdC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sn.set_context(\"paper\", font_scale = 1, rc = {\"font.size\": 20,\"axes.titlesize\": 15,\"axes.labelsize\": 30})\n",
        "sn.catplot(kind = 'count', data = heart_df, x = 'sex', hue = 'target', order = heart_df['sex'].sort_values().unique())\n",
        "plt.title('Variation of Sex for each target class')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHXy9aTIMurW",
        "colab_type": "text"
      },
      "source": [
        "age와 target의 관계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIzFvmfBMwUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sn.catplot(kind = 'count', data = heart_df,  x = 'age', hue = 'target')\n",
        "plt.title('Distribution of age vs sex with the target class')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-CmJ-4pNLXW",
        "colab_type": "text"
      },
      "source": [
        "성별과 나이의 밀도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czOs1IsyNLBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sn.set_context(\"paper\", font_scale = 1, rc = {\"font.size\": 20,\"axes.titlesize\": 15,\"axes.labelsize\": 30})\n",
        "sn.catplot(kind ='violin', data = heart_df, x = 'age', y='sex', hue = 'target')\n",
        "plt.title('Variation of Age for each target class')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGeSfmR7NRsY",
        "colab_type": "text"
      },
      "source": [
        "그림그리기위해서 임의로 성별 바꾼것을 원래 데이터로 변환 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXBJL6vHNR9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heart_df['sex'] = heart_df.sex.map({'female': 0, 'male': 1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx52hl5DNXbx",
        "colab_type": "text"
      },
      "source": [
        "p-value feature 지우기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Hub4WRNZtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tools import add_constant as add_constant\n",
        "\n",
        "heart_df_constant = add_constant(heart_df)\n",
        "\n",
        "st.chisqprob = lambda chisq, df: st.chi2.sf(chisq, df)#카이제곱 분포사용 감마 분포의 한종류\n",
        "\n",
        "cols=heart_df_constant.columns[:-1]\n",
        "\n",
        "model=sm.Logit(heart_df.target,heart_df_constant[cols])\n",
        "\n",
        "result=model.fit()\n",
        "print(result.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dtGIYTqNdjY",
        "colab_type": "text"
      },
      "source": [
        "위의 결과는 P 값이 선호 알파(5%)보다 높아서 심장 질환 확률과 통계적으로 유의미한 관계가 낮은 특성을 보여준다.\n",
        "\n",
        "여기서 후방 낙차 접근방식은 모든 속성의 P 값이 0.05 미만일 때까지 반복적으로 회귀 분석을 실행하여\n",
        "한 번에 P값이 가장 높은 속성을 제거하는 데 사용된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CMOAwr6NrW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_feature_elem (data_frame,dep_var,col_list):\n",
        "    \"\"\" Takes in the dataframe, the dependent variable and a list of column names, runs the regression repeatedly eleminating feature with the highest\n",
        "    P-value above alpha one at a time and returns the regression summary with all p-values below alpha\"\"\"\n",
        "\n",
        "    while len(col_list)>0 :\n",
        "        model=sm.Logit(dep_var,data_frame[col_list])\n",
        "        result=model.fit(disp=0)\n",
        "        largest_pvalue=round(result.pvalues,3).nlargest(1)\n",
        "        if largest_pvalue[0]<(0.05):\n",
        "            return result\n",
        "            break\n",
        "        else:\n",
        "            col_list=col_list.drop(largest_pvalue.index)\n",
        "\n",
        "result=back_feature_elem(heart_df_constant,heart_df.target,cols)\n",
        "\n",
        "print(result.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkowG6U1N4wE",
        "colab_type": "text"
      },
      "source": [
        "sex의 odds ratio에서 남성이 여성보다 심장병걸릴확률이 1-0.24만큼 낮다\n",
        "odd ratio는 비율이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc_C0-8QNkBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = np.exp(result.params)\n",
        "conf = np.exp(result.conf_int())\n",
        "conf['OR'] = params\n",
        "pvalue=round(result.pvalues,3)\n",
        "conf['pvalue']=pvalue\n",
        "conf.columns = ['CI 95%(2.5%)', 'CI 95%(97.5%)', 'Odds Ratio','pvalue']\n",
        "print ((conf))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAx4VMy4N8aM",
        "colab_type": "text"
      },
      "source": [
        "data processing\n",
        "\n",
        "수치형 스케일링 \n",
        "\n",
        "MinMaxScaler: 가장작은값을 0 가장 큰 값을 1로 바꿔줌 이상치에 취약\n",
        "standardScaler: 가우시안 분포로 만들어줌\n",
        "\n",
        "\n",
        "범주형 스케일링\n",
        "\n",
        "LaenlEncode: 값들을 0,1,2 이런 숫자로 바꿔줌\n",
        "\n",
        "inverse_transform :역변환\n",
        "\n",
        "OneHotEncode:희소행렬형태로 반환해줌\n",
        "\n",
        "Preprocessing:데이터 값이 너무 작으면 svm처럼 다른 컬럼 추가하는 전처리방식\n",
        "\n",
        "결측치의 수정,스케일의 변환 특성 추가 기능제공\n",
        "sklearn.impute,SimpleImputer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDbhpcZiN_sJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = heart_df.iloc[:, :-1].values\n",
        "y = heart_df.iloc[:, -1].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0,stratify=y)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler as ss\n",
        "\n",
        "sc = ss()\n",
        "x_train = sc.fit_transform(x_train)#스케일링 standardscaler 적용 평균이 0과 표준편차가 1이되도록 변환\n",
        "x_test = sc.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nhA1tyxOHxv",
        "colab_type": "text"
      },
      "source": [
        "logistic resgression\n",
        "solver: : L1제약조건,L2제약조건 2가지 모두 지원하여 이것은 작은 데이터에 적합한 알고리즘  saga 이것은  대용량 데이터에 적합한 알고리즘 \n",
        "\n",
        "penalty: L1,L2제약조건을 설정하는 하이퍼 파라미터이고 default는 L2\n",
        "\n",
        "class weight: 데이터에 직접 가중치를 설정하여 학습의 강도를 다르게 할수있다.\n",
        "\n",
        "C:alpha와 다르다 높은C를 설정할수록 낮은 강도의 제약조건이 설정되고  낮은C를 설정할수록 높은 강도의 제약조건이 설정된다\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhYdV_jbOkRI",
        "colab_type": "text"
      },
      "source": [
        "L2 제약조건: 모든 특성에 대한 가중치의 값을 0주변으로 위치하도록 제어하는 제약조건\n",
        "\n",
        "L1 제약조건: 별로 중요하지 않는 칼럼의 계수를 0으로 바꾸기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oqFYEOVOJs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier=LogisticRegression()\n",
        "classifier.fit(x_train,y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_train)\n",
        "print('Accuracy for train set for logistic regression={}'.format(sklearn.metrics.accuracy_score(y_train,y_pred)))\n",
        "\n",
        "\n",
        "y_pred=classifier.predict(x_test)\n",
        "print('Accuracy for test set for logistic regression={}'.format(sklearn.metrics.accuracy_score(y_test,y_pred)))\n",
        "print()\n",
        "#로지스틱 회귀 heatmap\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "plt.figure(figsize = (8,5))\n",
        "sn.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwrfp7zRQCkB",
        "colab_type": "text"
      },
      "source": [
        "SVM\n",
        "\n",
        "C:제약조건 강도설정\n",
        "\n",
        "gamma=가까이 있는 데이터의 가중치(높은 감마-> 좁은 영역에 큰 점수/낮은 감마->넓은 영역까지 접수)\n",
        "\n",
        "max_iter:최대 반복 획수를 지정한다\n",
        "\n",
        "class_weight:학습 분량 조절\n",
        "\n",
        "multi_class:3개이상 분류 \n",
        "\n",
        "penalty: 제약조건 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QOt63vdQGG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf')\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "\n",
        "y_pred = classifier.predict(x_train)\n",
        "print('Accuracy for train set for svm={}'.format(sklearn.metrics.accuracy_score(y_train,y_pred)))\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "print('Accuracy for test set for svm={}'.format(sklearn.metrics.accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skK8lJ5BTkKz",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaUxjfjxTm_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "\n",
        "y_pred = classifier.predict(x_train)\n",
        "print('Accuracy for train set for Naive Bayes  ={}'.format(sklearn.metrics.accuracy_score(y_train,y_pred)))\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "print('Accuracy for test set for Naive Bayes ={}'.format(sklearn.metrics.accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cPI5oDRTyCy",
        "colab_type": "text"
      },
      "source": [
        "Decision Tree(과적합이 심함, 데이터 범위 바깥 데이터가 들어오면 쓸모없음)\n",
        "\n",
        "max_depth=끝까지 학습하지 못하게하며 일반화 성능 높인다\n",
        "\n",
        "min_sample_split: 이놈이 계속 split 하면서 깊숙하게 들어가게하는데 만약 값이 2이면 한 노드에서 2개이하 데이터를 가지면 학습 멈추고 그만 들어가게함\n",
        "\n",
        "max_feature=많은 특성들중 최대 요만큼만 사용하라 라는 파라미터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaiU6_GDT1SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "classifier = DecisionTreeClassifier(random_state=50)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(x_train)\n",
        "\n",
        "print('Accuracy for train set for Decision Tree ={}'.format(sklearn.metrics.accuracy_score(y_train,y_pred)))\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "print('Accuracy for test set for Decision Tree ={}'.format(sklearn.metrics.accuracy_score(y_test,y_pred)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSQkejGLUBxy",
        "colab_type": "text"
      },
      "source": [
        "Random Forest(begging 앙상블 사용)\n",
        "전처리에 영향을 1도 안받음\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0FWI0UnUOjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(x_train)\n",
        "print('Accuracy for train set for Random Forest ={}'.format(sklearn.metrics.accuracy_score(y_train,y_pred)))\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "print('Accuracy for test set for Random Forest ={}'.format(sklearn.metrics.accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kgPz_QKYCc6",
        "colab_type": "text"
      },
      "source": [
        "앙상블기법\n",
        "\n",
        "voteing: 하나의 데이터셋을 가지고 여러가지 머신러닝 클래스에게 물어봐서 과반수 투표\n",
        "\n",
        "bagging:여러가지 데이터셋을 가지고 1개의 알고리즘으로 여러개의 예측기 생성\n",
        "\n",
        "boosting:취합을 하지 않고 점진적으로 학습시키면서 연결한다.\n",
        "첫번째에게 물어봐서 틀린것 보완 두번째에게서 틀린것 보완 이런식으로 점진적인 방법을 boosting이라고함\n",
        "\n",
        "가중치를 높여가면서 하는 adaboost가 있고 틀린 오차를 학습시키는 gradient boosting이 있음\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zVJeYWCax21",
        "colab_type": "text"
      },
      "source": [
        "Voting 앙상블 with KFold\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRTQx5k4YCBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "knn_model=KNeighborsClassifier(n_neighbors=5)\n",
        "svc_model=SVC()\n",
        "dt_model=DecisionTreeClassifier()\n",
        "lr_model=LogisticRegression()\n",
        "\n",
        "ensemble=VotingClassifier(estimators=[('lr',lr_model),\n",
        "                                      ('knn',knn_model),\n",
        "                                      ('svc',svc_model),\n",
        "                                      ('dt',dt_model)])\n",
        "\n",
        "\n",
        "lr_model.fit(x_train,y_train)\n",
        "knn_model.fit(x_train,y_train)\n",
        "svc_model.fit(x_train,y_train)\n",
        "dt_model.fit(x_train,y_train)\n",
        "ensemble.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "kfold=KFold(n_splits=5,shuffle=True)\n",
        "ensemble_scores=cross_val_score(ensemble,x,y,cv=kfold,n_jobs=-1)\n",
        "\n",
        "print('학습 평가(lr):',lr_model.score(x_test,y_test))\n",
        "print('학습 평가(knn):',knn_model.score(x_test,y_test))\n",
        "print('학습 평가(svc):',svc_model.score(x_test,y_test))\n",
        "print('학습 평가(dt):',dt_model.score(x_test,y_test))\n",
        "print('학습 평가(ensemble):',ensemble.score(x_test,y_test))\n",
        "print('kfold 학습평가(ensemble)',ensemble_scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxDAK5p9c1iK",
        "colab_type": "text"
      },
      "source": [
        "Boosting 앙상블\n",
        "\n",
        "weaker가 stronger가 되어갈때 데이터의 가중치를 조절해 가면서 stringer가 되어가는 Adaboost\n",
        "\n",
        "weaker가 stronger가 되어갈 때 잔여 오차를 재차 학습하면 stronger가 되어가는 GradientBoost가 있다.\n",
        "\n",
        "adaboost는 내부 예측기를 지정해서 돌리지만 gradientboost는 내부예측기는 decision tree사용\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myThq88Bdwpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "#adaboost\n",
        "base_model=DecisionTreeClassifier(\n",
        "    max_depth=3,\n",
        "    max_features=0.2,\n",
        "    class_weight='balanced',\n",
        "    random_state=1\n",
        ")\n",
        "\n",
        "ada_model=AdaBoostClassifier(\n",
        "    base_estimator=base_model,\n",
        "    n_estimators=1000,\n",
        "    learning_rate=1.,\n",
        "    random_state=1\n",
        ").fit(x_train,y_train)\n",
        "\n",
        "print('정확도(ada_model):',ada_model.score(x_test,y_test))\n",
        "\n",
        "#gradient boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_model=GradientBoostingClassifier(\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=10000,\n",
        "    max_depth=3,#보통 5이상 두지 않는다\n",
        "    max_features=0.6,\n",
        "    subsample=0.7, #과적합 방지 하이퍼 파라미터\n",
        "    random_state=1).fit(x_train,y_train)\n",
        "\n",
        "print('정확도(gb_model):', gb_model.score(x_test,y_test))\n",
        "\n",
        "print(\"feature importance::\",gb_model.feature_importances_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZEqf13uVz9E",
        "colab_type": "text"
      },
      "source": [
        "stacking 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qF03ZJtVzqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "def get_stacking_data(model, x_train,y_train,x_test,n_folds=5):\n",
        "    kfold=KFold(n_splits=n_folds,random_state=0,shuffle=True)\n",
        "    train_fold_predict=np.zeros((x_train.shape[0],1))\n",
        "    test_predict=np.zeros((x_test.shape[0],n_folds))\n",
        "    print('model:',model.__class__.__name__)\n",
        "\n",
        "    for cnt, (train_index,valid_index) in enumerate(kfold.split(x_train)):\n",
        "        x_train_ = x_train[train_index]\n",
        "        y_train_=y_train[train_index]\n",
        "        x_validation=x_train[valid_index]\n",
        "\n",
        "        model.fit(x_train_,y_train_)\n",
        "        train_fold_predict[valid_index,:]=model.predict(x_validation).reshape(-1,1)\n",
        "        test_predict[:,cnt]=model.predict(x_test)\n",
        "\n",
        "    test_predict_mean=np.mean(test_predict,axis=1).reshape(-1,1)\n",
        "\n",
        "    return train_fold_predict,test_predict_mean\n",
        "\n",
        "svm = SVC(kernel = 'rbf')\n",
        "rf = RandomForestClassifier(n_estimators = 10)\n",
        "lr=LogisticRegression()\n",
        "\n",
        "svm_train,svm_test=get_stacking_data(svm,x_train,y_train,x_test)\n",
        "rf_train,rf_test=get_stacking_data(rf,x_train,y_train,x_test)\n",
        "lr_train,lr_test=get_stacking_data(lr,x_train,y_train,x_test)\n",
        "\n",
        "new_x_train=np.concatenate((svm_train,rf_train,lr_train),axis=1)\n",
        "new_x_test=np.concatenate((svm_test,rf_test,lr_test),axis=1)\n",
        "\n",
        "knn=KNeighborsClassifier(n_neighbors=2,n_jobs=-1)     \n",
        "#knn은 scaling을 사용하고 해야한다 knn이 거리기반이어서 범위가 같아야한다 \n",
        "\n",
        "knn.fit(new_x_train,y_train)\n",
        "stack_pred=knn.predict(new_x_test)\n",
        "print(\"정확도: \",(sklearn.metrics.accuracy_score(stack_pred,y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}